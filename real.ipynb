{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "real.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4065ZmzGEMulZIG3s5IIw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayank-goyal2424/Learning.it/blob/master/real.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHdA91RH7UYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsIkbDg_9jaA",
        "colab_type": "code",
        "outputId": "67c55f35-5ed6-4a59-dc8a-20165c1ad3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary c"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KnAJNh_7f1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_(img, conv_filter):\n",
        "    filter_size = conv_filter.shape[1]\n",
        "    result = numpy.zeros((img.shape))\n",
        "    #Looping through the image to apply the convolution operation.\n",
        "    for r in numpy.uint16(numpy.arange(filter_size/2.0, \n",
        "                          img.shape[0]-filter_size/2.0+1)):\n",
        "        for c in numpy.uint16(numpy.arange(filter_size/2.0, \n",
        "                                           img.shape[1]-filter_size/2.0+1)):\n",
        "            \"\"\"\n",
        "            Getting the current region to get multiplied with the filter.\n",
        "            How to loop through the image and get the region based on \n",
        "            the image and filer sizes is the most tricky part of convolution.\n",
        "            \"\"\"\n",
        "            curr_region = img[r-numpy.uint16(numpy.floor(filter_size/2.0)):r+numpy.uint16(numpy.ceil(filter_size/2.0)), \n",
        "                              c-numpy.uint16(numpy.floor(filter_size/2.0)):c+numpy.uint16(numpy.ceil(filter_size/2.0))]\n",
        "            #Element-wise multipliplication between the current region and the filter.\n",
        "            curr_result = curr_region * conv_filter\n",
        "            conv_sum = numpy.sum(curr_result) #Summing the result of multiplication.\n",
        "            result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.\n",
        "            \n",
        "    #Clipping the outliers of the result matrix.\n",
        "    final_result = result[numpy.uint16(filter_size/2.0):result.shape[0]-numpy.uint16(filter_size/2.0), \n",
        "                          numpy.uint16(filter_size/2.0):result.shape[1]-numpy.uint16(filter_size/2.0)]\n",
        "    return final_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji45U_IM7gAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv(img, conv_filter):\n",
        "    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\n",
        "        if img.shape[-1] != conv_filter.shape[-1]:\n",
        "            print(\"Error: Number of channels in both image and filter must match.\")\n",
        "            sys.exit()\n",
        "    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.\n",
        "        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')\n",
        "        sys.exit()\n",
        "    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\n",
        "        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')\n",
        "        sys.exit()\n",
        "\n",
        "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
        "    feature_maps = numpy.zeros((img.shape[0]-conv_filter.shape[1]+1, \n",
        "                                img.shape[1]-conv_filter.shape[1]+1, \n",
        "                                conv_filter.shape[0]))\n",
        "\n",
        "    # Convolving the image by the filter(s).\n",
        "    for filter_num in range(conv_filter.shape[0]):\n",
        "        print(\"Filter \", filter_num + 1)\n",
        "        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.\n",
        "        \"\"\" \n",
        "        Checking if there are mutliple channels for the single filter.\n",
        "        If so, then each channel will convolve the image.\n",
        "        The result of all convolutions are summed to return a single feature map.\n",
        "        \"\"\"\n",
        "        if len(curr_filter.shape) > 2:\n",
        "            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.\n",
        "            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.\n",
        "                conv_map = conv_map + conv_(img[:, :, ch_num], \n",
        "                                  curr_filter[:, :, ch_num])\n",
        "        else: # There is just a single channel in the filter.\n",
        "            conv_map = conv_(img, curr_filter)\n",
        "        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.\n",
        "    return feature_maps # Returning all feature maps."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUDVY1537gMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pooling(feature_map, size=2, stride=2):\n",
        "    #Preparing the output of the pooling operation.\n",
        "    pool_out = numpy.zeros((numpy.uint16((feature_map.shape[0]-size+1)/stride+1),\n",
        "                            numpy.uint16((feature_map.shape[1]-size+1)/stride+1),\n",
        "                            feature_map.shape[-1]))\n",
        "    for map_num in range(feature_map.shape[-1]):\n",
        "        r2 = 0\n",
        "        for r in numpy.arange(0,feature_map.shape[0]-size+1, stride):\n",
        "            c2 = 0\n",
        "            for c in numpy.arange(0, feature_map.shape[1]-size+1, stride):\n",
        "                pool_out[r2, c2, map_num] = numpy.max([feature_map[r:r+size,  c:c+size]])\n",
        "                c2 = c2 + 1\n",
        "            r2 = r2 +1\n",
        "    return pool_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vLwxDO07ga7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(feature_map):\n",
        "    #Preparing the output of the ReLU activation function.\n",
        "    relu_out = numpy.zeros(feature_map.shape)\n",
        "    for map_num in range(feature_map.shape[-1]):\n",
        "        for r in numpy.arange(0,feature_map.shape[0]):\n",
        "            for c in numpy.arange(0, feature_map.shape[1]):\n",
        "                relu_out[r, c, map_num] = numpy.max([feature_map[r, c, map_num], 0])\n",
        "    return relu_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8QikMf7gnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_filter = np.zeros((2,3,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCx-BeSH7gzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_filter[0, :, :] = np.array([[[-1, 0, 1], \n",
        "                                   [-1, 0, 1], \n",
        "                                   [-1, 0, 1]]])\n",
        "#Horizontal Edge Detection Filter\n",
        "l1_filter[1, :, :] = np.array([[[1,   1,  1], \n",
        "                                   [0,   0,  0], \n",
        "                                   [-1, -1, -1]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xUftNI3KncR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "db41c9ab-1e75-47cd-b81a-6eef4339a53d"
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.imshow(x_train[122].reshape(28,28),cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h01IM4ZOKm9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_feature_map = conv(img, l1_filter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKAds1cdKnzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_feature_map_relu = relu(l1_feature_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM17cu_eKoJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_feature_map_relu_pool = pooling(l1_feature_map_relu, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3tgd9bO7hAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "def model():\n",
        "  img=?\n",
        "  l1_filter = np.zeros((2,3,3))\n",
        "  l1_filter[0, :, :] = np.array([[[-1, 0, 1], \n",
        "                                   [-1, 0, 1], \n",
        "                                   [-1, 0, 1]]])\n",
        "  #Horizontal Edge Detection Filter\n",
        "  l1_filter[1, :, :] = np.array([[[1,   1,  1], \n",
        "                                   [0,   0,  0], \n",
        "                                   [-1, -1, -1]]])\n",
        "  l1_feature_map = conv(img, l1_filter)\n",
        "  l1_feature_map_relu = relu(l1_feature_map)\n",
        "  l1_feature_map_relu_pool = pooling(l1_feature_map_relu, 2, 2)\n",
        "  l2_filter = numpy.random.rand(3, 5, 5, l1_feature_map_relu_pool.shape[-1])\n",
        "  #print(\"\\n**Working with conv layer 2**\")\n",
        "  l2_feature_map = conv(l1_feature_map_relu_pool, l2_filter)\n",
        "  #print(\"\\n**ReLU**\")\n",
        "  l2_feature_map_relu = relu(l2_feature_map)\n",
        "  #print(\"\\n**Pooling**\")\n",
        "  l2_feature_map_relu_pool = pooling(l2_feature_map_relu, 2, 2)\n",
        "  #print(\"**End of conv layer 2**\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBKX9BGhO9Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}